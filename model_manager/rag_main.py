import os
import csv
from haystack import Pipeline
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder
from haystack.components.preprocessors import DocumentSplitter
from component.generator import LocalLLMGenerator
from haystack import Document

# ================== ä¸»æµç¨‹ ==================
# 1. åŠ è½½ CSV æ–‡ä»¶
csv_path = "/work/zxx/demon/model_manager/sample_rules.csv" # âœ… ä¿®æ”¹ä¸ºä½ çš„ CSV æ–‡ä»¶è·¯å¾„
if not os.path.exists(csv_path):
    # å¦‚æœæ‰¾ä¸åˆ°åŸå§‹è·¯å¾„ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹è·¯å¾„
    example_csv_path = "./sample_rules.csv"
    if os.path.exists(example_csv_path):
        csv_path = example_csv_path
        print(f"âš ï¸ ä½¿ç”¨ç¤ºä¾‹è§„åˆ™æ–‡ä»¶: {csv_path}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {csv_path}")
        print("è¯·åˆ›å»ºä¸€ä¸ªåŒ…å«è§„åˆ™çš„CSVæ–‡ä»¶ã€‚")
        exit(1)

documents = []
try:
    with open(csv_path, "r", encoding="utf-8") as csvfile:
        # âœ… ä½¿ç”¨ DictReaderï¼Œå®ƒä¼šå°†ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
        reader = csv.DictReader(csvfile)
        for i, row in enumerate(reader):
            # âœ… å‡è®¾ CSV æœ‰ 'character' å’Œ 'rule' åˆ—
            character = row.get('character', '').strip()
            rule = row.get('rule', '').strip()
            
            # âœ… æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦ä¸ºç©º
            if not character or not rule:
                print(f"âš ï¸ è­¦å‘Š: CSV æ–‡ä»¶ç¬¬ {i+2} è¡Œç¼ºå°‘ 'character' æˆ– 'rule' å­—æ®µï¼Œå·²è·³è¿‡ã€‚è¡Œå†…å®¹: {row}")
                continue

            # âœ… æ„é€ æ–‡æ¡£å†…å®¹
            content = f"{character}çš„è®¾è®¡è§„åˆ™ï¼š{rule}"
            
            # âœ… æ„é€ å…ƒæ•°æ®ï¼ŒåŒ…å« CSV ä¸­çš„æ‰€æœ‰åˆ—ï¼ˆæ–¹ä¾¿åç»­ä½¿ç”¨ï¼‰
            meta = {k.strip(): v.strip() for k, v in row.items() if k and v} # æ¸…ç†é”®å’Œå€¼çš„ç©ºæ ¼
            
            documents.append(Document(content=content, meta=meta))

    print(f"âœ… æˆåŠŸä» CSV åŠ è½½ {len(documents)} æ¡è§„åˆ™ã€‚")

except Exception as e:
    print(f"âŒ è¯»å–æˆ–è§£æ CSV æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    exit(1)

# 2. åˆå§‹åŒ– Document Store
document_store = InMemoryDocumentStore()

# 3. åˆ†å—å’ŒåµŒå…¥
splitter = DocumentSplitter(
    split_by="word",           
    split_length=300,          
    split_overlap=50,          
    language="zh"              
)
splitter.warm_up()
split_docs = splitter.run(documents=documents)["documents"]

print(f"âœ… æ–‡æ¡£åˆ†å—å®Œæˆï¼ŒåŸå§‹æ–‡æ¡£æ•°: {len(documents)}ï¼Œåˆ†å—åæ–‡æ¡£æ•°: {len(split_docs)}")

# æ‰“å°åˆ†å—åçš„å‰å‡ ä¸ªæ–‡æ¡£ä½œä¸ºç¤ºä¾‹
print("\n" + "="*80)
print("ğŸ“‹ åˆ†å—åæ–‡æ¡£ç¤ºä¾‹ï¼š")
print("="*80)
for i, doc in enumerate(split_docs[:3]):  # åªæ‰“å°å‰3ä¸ªç¤ºä¾‹
    print(f"æ–‡æ¡£ {i+1}:")
    print(f"å†…å®¹: {doc.content[:100]}...")  # åªæ‰“å°å‰100ä¸ªå­—ç¬¦
    print(f"å…ƒæ•°æ®: {doc.meta}")
    print("-"*80)

# ç”Ÿæˆæ–‡æ¡£åµŒå…¥
doc_embedder = SentenceTransformersDocumentEmbedder(
    model="/work/models/sentence-transformers/all-MiniLM-L6-v2"
)
doc_embedder.warm_up()
embedded_docs = doc_embedder.run(split_docs)

print(f"âœ… æ–‡æ¡£åµŒå…¥å®Œæˆï¼Œå…± {len(embedded_docs['documents'])} ä¸ªæ–‡æ¡£åµŒå…¥")

# å°†åµŒå…¥åçš„æ–‡æ¡£å†™å…¥ document_store
document_store.write_documents(embedded_docs["documents"])
print(f"âœ… æ–‡æ¡£å·²æˆåŠŸå†™å…¥æ•°æ®åº“")

# 5. åˆå§‹åŒ–æ£€ç´¢å™¨
retriever = InMemoryEmbeddingRetriever(document_store=document_store)

# 6. åˆå§‹åŒ–ç”Ÿæˆå™¨
generator = LocalLLMGenerator(
    model_path="/work/models/Qwen/Qwen3-8B",  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
    device="cuda"
)

# 7. æ„å»º Prompt
template = """
æ ¹æ®ä»¥ä¸‹è§„åˆ™å›ç­”é—®é¢˜ï¼š

{% for doc in documents %}
- {{ doc.content|string }}
{% endfor %}

é—®é¢˜ï¼š{{ query|string }}
è¯·æ ¹æ®ä¸Šè¿°è§„åˆ™å›ç­”é—®é¢˜ï¼Œå¦‚æœè§„åˆ™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•æ ¹æ®æä¾›çš„è§„åˆ™å›ç­”è¯¥é—®é¢˜ã€‚
"""

prompt_builder = PromptBuilder(
    template=template,
    required_variables=["documents", "query"]
)

# 8. æ„å»º Pipeline
pipe = Pipeline()

# åˆå§‹åŒ–ç»„ä»¶
text_embedder = SentenceTransformersTextEmbedder(model="/work/models/sentence-transformers/all-MiniLM-L6-v2")
text_embedder.warm_up()

retriever = InMemoryEmbeddingRetriever(document_store=document_store)
prompt_builder = PromptBuilder(template=template)
generator = LocalLLMGenerator(
    model_path="/work/models/Qwen/Qwen3-8B",  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
    device="cuda"
)

# æ·»åŠ ç»„ä»¶
pipe.add_component("text_embedder", text_embedder)
pipe.add_component("retriever", retriever)
pipe.add_component("prompt_builder", prompt_builder)
pipe.add_component("generator", generator)

# è¿æ¥ç»„ä»¶
pipe.connect("text_embedder.embedding", "retriever.query_embedding")
pipe.connect("retriever", "prompt_builder.documents")
# âœ… ä¸å†ä» text_embedder ä¼  queryï¼Œè€Œæ˜¯ä»å¤–éƒ¨ç›´æ¥ä¼ å…¥ query æ–‡æœ¬
pipe.connect("prompt_builder", "generator.prompt")

# 9. æé—®æµ‹è¯•
queries = [
    "ç‚­æ²»éƒçš„è€³ç¯åœ¨ä¸­å›½å¤§é™†ä½¿ç”¨æ—¶æœ‰ä»€ä¹ˆé™åˆ¶ï¼Ÿ",
    "ç¥¢è±†å­çš„ç«¹ç­’è®¾è®¡è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ",
]
for query_text in queries:
    print("\n" + "=" * 80)
    print("ğŸ“Œ é—®é¢˜:", query_text)
    print("=" * 80)
    try:
        # å…ˆè·å–åµŒå…¥çš„æŸ¥è¯¢å‘é‡
        query_embedding = text_embedder.run(text=query_text)["embedding"]
        
        # ä½¿ç”¨æ£€ç´¢å™¨è·å–ç›¸å…³æ–‡æ¡£
        retrieved_docs = retriever.run(query_embedding=query_embedding, top_k=5)["documents"]
        
        # æ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ°é†’ç›®ç¾è§‚çš„æ¡†ä¸­
        print("\n" + "ğŸ”" + "#" * 78 + "ğŸ”")
        print(f"{'ğŸ” æ•°æ®åº“æ£€ç´¢ç»“æœ':^78}")
        print("ğŸ”" + "#" * 78 + "ğŸ”")
        
        for i, doc in enumerate(retrieved_docs):
            print(f"ğŸ” æ£€ç´¢ç»“æœ {i+1}:")
            print(f"ğŸ” å†…å®¹: {doc.content}")
            print(f"ğŸ” å…ƒæ•°æ®: {doc.meta}")
            print("ğŸ”" + "-" * 78 + "ğŸ”")
        
        print("ğŸ”" + "#" * 78 + "ğŸ”\n")
        
        # è¿è¡Œå®Œæ•´çš„ç®¡é“è·å–ç­”æ¡ˆ
        response = pipe.run(
            data={
                "text_embedder": {"text": query_text},
                "retriever": {"top_k": 150},
                "prompt_builder": {"query": query_text},  # âœ… å…³é”®ï¼šæ‰‹åŠ¨ä¼  query
                "generator": {}
            }
        )
        
        answer = response["generator"]["replies"][0]
        
        # æ‰“å°ç”Ÿæˆçš„ç­”æ¡ˆåˆ°é†’ç›®ç¾è§‚çš„æ¡†ä¸­
        print("\n" + "ğŸ“" + "=" * 78 + "ğŸ“")
        print(f"{'ğŸ“ ç”Ÿæˆç­”æ¡ˆ':^78}")
        print("ğŸ“" + "=" * 78 + "ğŸ“")
        print(f"{answer}")
        print("ğŸ“" + "=" * 78 + "ğŸ“\n")
        
    except Exception as e:
        print("âŒ é”™è¯¯:", str(e))